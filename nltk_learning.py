# tokenizing, grouping things...
#word tokenizers... sentence tokenizer, splits words and sentences
#coropora is just a body of text, like a bunch of text, i.e. medical jornals, presidental speech, english lang
# lexicon, words and thier meanings..., doctors speak and english speak, different speak  different meaning of language text...

from nltk.tokenize import sent_tokenize, word_tokenize

example_text = 'Hello there, how are you doing today? The weather is reat and Python is awesome. The sky is purple and I don't know.'




